[
  {
    "objectID": "Take-Home_Ex/Take-Home Ex1.html",
    "href": "Take-Home_Ex/Take-Home Ex1.html",
    "title": "Take-home Exercise 1 - Geospatial Analytics for Social Good",
    "section": "",
    "text": "Water is an important resource to mankind. Clean and accessible water is critical to human health. It provides a healthy environment, a sustainable economy, reduces poverty and ensures peace and security. Yet over 40% of the global population does not have access to sufficient clean water. By 2025, 1.8 billion people will be living in countries or regions with absolute water scarcity, according to UN-Water. The lack of water poses a major threat to several sectors, including food security. Agriculture uses about 70% of the world’s accessible freshwater.\nDeveloping countries are most affected by water shortages and poor water quality. Up to 80% of illnesses in the developing world are linked to inadequate water and sanitation. Despite technological advancement, providing clean water to the rural community is still a major development issues in many countries globally, especially countries in the Africa continent.\nTo address the issue of providing clean and sustainable water supply to the rural community, a global Water Point Data Exchange (WPdx) project has been initiated. The main aim of this initiative is to collect water point related data from rural areas at the water point or small water scheme level and share the data via WPdx Data Repository, a cloud-based data library. What is so special of this project is that data are collected based on WPDx Data Standard.\n\n\n\nThis study aims to apply appropriate global and local measures of spatial Association techniques to reveal the spatial patterns of Not Functional water points in Nigeria.\n\n\n\nUsing the appropriate R packages, we will need to:\n\nPrepare the dataset and save it in simple feature data frameformat, as well as derive the proportion of functional and non-functional water point at LGA level\nConduct thematic mapping analysis to examine the spatial distribution of functional and non-functional water point rate at LGA level\nConduct hotspot areas and outliers/clusters maps of functional and non0functional water point rate at LGA level"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home Ex1.html#setup",
    "href": "Take-Home_Ex/Take-Home Ex1.html#setup",
    "title": "Take-home Exercise 1 - Geospatial Analytics for Social Good",
    "section": "2. Setup",
    "text": "2. Setup\n\n2.1 Packages Used\nThe R packages that we will be using for this analysis area:\n\nsf: used for importing, managing, and processing geospatial data\ntidyverse: used for wrangling attribute data\nspdep: used for computing spatial weights, global and local spatial auto-correlation statistics\ntmap: used for creating cartographic quality choropleth map\nfunModeling: used for exploratory data analysis, data preparation and model performance\n\nIn addition, the following tidyverse packages will be used:\n\ntidyr for manipulating and tidying data\ndplyr for wrangling and transforming data\nggplot2 for visualising data\n\n\n\n2.2 Datasets Used\n2 geospatial datasets will be utilized for this study:\n\ngeo_export_338e5689-bd72-4866-bfde-8997933e9897\nWPdx+ dataset from WPdx Global Data Repositories\nnga_admbnda_adm2_osgof_20190417\nNigeria Level-2 Administrative Boundary (also known as Local Government Area) polygon features GIS data from geoBoundaries\n\n\n\n2.3 Launching the packages in R\nThe code chunk below is used to perform the following tasks:\n\ncreating a package list containing the necessary R packages,\nchecking if the R packages in the package list have been installed in R,\n\nif they have yet to be installed, RStudio will installed the missing packages,\n\nlaunching the packages into R environment.\n\n\npacman::p_load(sf, spdep, tmap, tidyverse, funModeling)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home Ex1.html#data-preparation",
    "href": "Take-Home_Ex/Take-Home Ex1.html#data-preparation",
    "title": "Take-home Exercise 1 - Geospatial Analytics for Social Good",
    "section": "3. Data Preparation",
    "text": "3. Data Preparation\nIn this section, we will bring geospatial data into R environment. The geospatial data is in ESRI shapefile format.\n\n3.1 Import water point shapefile into R environment\nThe code chunk below uses st_read() of sf package to import Nigeria shapefile into R. The imported shapefile will be simple features Object of sf.\n\nwp <- st_read(dsn = \"geodata\",\n              layer = \"geo_export_338e5689-bd72-4866-bfde-8997933e9897\",\n              crs = 4326) %>%\n  filter(clean_coun == \"Nigeria\") %>%\n  select(1:4, 13:15, 23, 36:40)\n\nThe code chunk below uses write_rds() of readr package to save the extracted sf data table (i.e. wp) into an output in rds data format. The output file is called wp_nga.rds and it is saved in geodata sub-folder.\n\nwp_nga <- write_rds(wp, \"geodata/wp_nga.rds\")\n\n\n\n3.2 Import Nigeria LGA boundary data into R environment\nWe are going to import LGA boundary data into R environment using the following code chunk, st_read() of sf package. It is used to import nga_admbnda_adm2_osgof_20190417 shapefile and save the imported geospatial data into simple feature data table.\n\nnga <- st_read(dsn = \"geodata\",\n               layer = \"nga_admbnda_adm2_osgof_20190417\",\n               crs = 4326)\n\n\n\n3.3 Recoding NA values into string\nUse replace_na() to recode all the NA values in status_cle field into the Unknown.\n\nwp_nga <- read_rds(\"geodata/wp_nga.rds\") %>%\n  mutate(status_cle = replace_na(status_cle, \"Unknown\"))"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home Ex1.html#exploratory-spatial-data-analysis",
    "href": "Take-Home_Ex/Take-Home Ex1.html#exploratory-spatial-data-analysis",
    "title": "Take-home Exercise 1 - Geospatial Analytics for Social Good",
    "section": "4. Exploratory Spatial Data Analysis",
    "text": "4. Exploratory Spatial Data Analysis\nUse freq() of funModeling package to display the distribution of status_cle field in wp_nga.\n\nfreq(data = wp_nga,\n     input = \"status_cle\")\n\n\n4.1 Extract functional water point data\nIn the code chunk below, filter() of dplyr is used to select functional water points.\n\nwpt_functional <- wp_nga %>%\n  filter(status_cle %in%\n           c(\"Functional\", \n             \"Functional but not in use\",\n             \"Functional but needs repair\"))\n\nfreq(data=wpt_functional, \n     input = 'status_cle')\n\n\n\n4.2 Extract non-functional water point data\nIn the code chunk below, filter() of dplyr is used to select non-functional water points.\n\nwpt_nonfunctional <- wp_nga %>%\n  filter(status_cle %in%\n           c(\"Abandoned/Decommissioned\", \n             \"Abandoned\",\n             \"Non-Functional\",\n             \"Non functional due to dry season\",\n             \"Non-Functional due to dry season\"))\n\nfreq(data=wpt_nonfunctional, \n     input = 'status_cle')\n\n\n\n4.3 Extract water point data with Unknown class\nIn the code chunk below, filter() of dplyr is used to select unknown water points.\n\nwpt_unknown <- wp_nga %>%\n  filter(status_cle == \"Unknown\")\n\n\n\n4.4 Performing Point-in-Polygon Count\nThe code chunk below performs 2 operations at one go. Firstly, it uses st_intersects() to identify the various water point types (e.g. total, functional, non-functional and unknown) located inside each LGA boundary. Next, length() of Base R is used to calculate the number of water points that fall within each LGA boundary.\n\nnga_wp <- nga %>% \n  mutate(`total wpt` = lengths(\n    st_intersects(nga, wp_nga))) %>%\n  mutate(`wpt functional` = lengths(\n    st_intersects(nga, wpt_functional))) %>%\n  mutate(`wpt non-functional` = lengths(\n    st_intersects(nga, wpt_nonfunctional))) %>%\n  mutate(`wpt unknown` = lengths(\n    st_intersects(nga, wpt_unknown)))\n\n\n\n4.5 Saving the Analytical Data Table\nThe code chunk below uses mutate() of dplyr package to derive 2 fields namely pct_functional and pct_non-functional. In order to keep the file size small, select() of dplyr is used to retain on the relevant fields.\n\nnga_wp <- nga_wp %>%\n  mutate(pct_functional = `wpt functional`/`total wpt`) %>%\n  mutate(`pct_non-functional` = `wpt non-functional`/`total wpt`) %>%\n  select(3:4, 9:10, 18:23)\n\nThereafter, we will save the sf data table in rds format for subsequent analysis.\n\nwrite_rds(nga_wp, \"geodata/nga_wp.rds\")"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home Ex1.html#geospatial-visualization-analysis",
    "href": "Take-Home_Ex/Take-Home Ex1.html#geospatial-visualization-analysis",
    "title": "Take-home Exercise 1 - Geospatial Analytics for Social Good",
    "section": "5. Geospatial Visualization & Analysis",
    "text": "5. Geospatial Visualization & Analysis\n\n5.1 Thematic Mapping of Functional and Non-Functional Water Points at LGA level\nIn order to draw a choropleth map, we will use qtm() of tmap package. Small choropleth maps are created with tmap_arrange().\n\nnga_wp <- read_rds(\"geodata/nga_wp.rds\")\ntotal <- qtm(nga_wp, \"total wpt\")\nwp_functional <- qtm(nga_wp, \"wpt functional\")\nwp_nonfunctional <- qtm(nga_wp, \"wpt non-functional\")\nunknown <- qtm(nga_wp, \"wpt unknown\")\n\ntmap_arrange(total, wp_functional, wp_nonfunctional, unknown, asp=1, ncol=2)\n\n\n\n5.2 Global Spatial Autocorrelation\nIn this section, we will compute global spatial autocorrelation statistics and perform spatial complete randomness test for global spatial autocorrelation.\n\n5.2.1 Computing Contiguity Spatial Weights\nIn the code chunk below, poly2nb() of spdep package is used to compute the contiguity weight matrices for the LGA. We will compute Queen contiguity weight matrix.\n\nwm_q <- poly2nb(nga_wp, \n                queen=TRUE)\n\nsummary(wm_q)\n\nThe summary report above shows that there are 774 area units in Nigera. The most connected area unit has 14 neighbours. There are 2 area units with only 1 neighbour.\n\n\n5.2.2 Row-standardized weights matrix\nAlternatively, we can assign weights to each neighbouring polygon. In this study, each of the neighbouring polygon will be assigned equal weight (style = “W”). This is accomplished by assigning the fraction 1/(# of neighbors) to each neighboring county then summing the weighted income values.\n\nrswm_q <- nb2listw(wm_q, \n                   style=\"W\", \n                   zero.policy = TRUE)\n\nset.ZeroPolicyOption(TRUE)\n\nrswm_q\n\n\n\n5.2.3 Performing Moran’s I test\nUsing localmoran() function of spdep, we will compute local Moran’s I. We will compute local indicator values, given a set of standard deviation values and listw objective providing the neighbour weighting information of the polygon associated with standard deviation values.\nThe code chunk below is used to compute local Moran’s I of non-functional waterpoints at the LGA.\n\nmoran.test(nga_wp$`wpt non-functional`, \n           listw = rswm_q, \n           zero.policy = TRUE, \n           na.action=na.omit)\n\nThe above statistical output illustrates that the null hypothesis i.e. observed spatial pattern of values is equally likely as other spatial pattern can be rejected. There is sufficient evidence to show that regions with higher percentage of non-functional water points are dependent on those at other (neighbouring) locations.\n\n\n5.2.4 Geary’s C test\nThe code chunk below performs Geary’s C test for spatial autocorrelation by using geary.test() of spdep.\n\ngeary.test(nga_wp$`wpt non-functional`, listw=rswm_q)\n\nThe above statistical output illustrates that the null hypothesis i.e. observed spatial pattern of values is similar from their immediate neighbours can be rejected. There is sufficient evidence to show that regions with higher percentage of non-functional water points are dissimilar to their (neighbouring) locations.\n\n\n\n5.3 Cluster and Outlier Analysis\n\n5.3.1 Computing local Moran’s I\nTo compute local Moran’s I, the localmoran() function of spdep will be used. It computes the local Moran’s I statistic values, given a set of standard deviation and a listw object providing neighbour weighting information for the polygon associated with standard deviation.\nThe code chunk below is used to compute local Moran’s I of non-functional water point at the county level.\n\nfips <- order(nga_wp$ADM2_EN)\nlocalMI <- localmoran(nga_wp$`wpt non-functional`, rswm_q)\nhead(localMI)\n\nThe code chunk below list the content of the local Moran matrix derived by using printCoefmat().\n\nprintCoefmat(data.frame(\n  localMI[fips,], \n  row.names = nga_wp$ADM2_PCODE[fips]),\n  check.names=FALSE)\n\n\n\n5.3.2 Mapping both local Moran’s I values and p-values\nThe code chunk below is meant to append the local Moran’s I dataframe (i.e. localMI) onto Nigera Spatial Polygon Data Frame.\n\nnga_wp.localMI <- cbind(nga_wp,localMI) %>%\n  rename(Pr.Ii = Pr.z....E.Ii..)\n\nUsing choropleth mapping functions of tmap package, we will plot the local Moran’s I and p-values with the code chunk below.\n\nlocalMI.map <- tm_shape(nga_wp.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\",\n          palette = \"RdBu\",\n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\npvalue.map <- tm_shape(nga_wp.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)\n\n\n\n5.3.3 Creating LISA map classes\nThe code chunk below show the steps to prepare a LISA cluster map.\n\nquadrant <- vector(mode=\"numeric\",length=nrow(localMI))\n\nNext, derives the spatially lagged variable of interest (i.e. wpt_nonfunctional) and centers the spatially lagged variable around its mean.\n\nnga_wp$lag_nonfunctional <- lag.listw(rswm_q, nga_wp$`wpt non-functional`)\n\nDV <- nga_wp$lag_nonfunctional - mean(nga_wp$lag_nonfunctional)     \n\nThis is follow by centering the local Moran’s around the mean.\n\nLM_I <- localMI[,1] - mean(localMI[,1])    \n\nNext, we will set a statistical significance level for the local Moran.\n\nsignif <- 0.05 \n\nThese four command lines define the low-low (1), low-high (2), high-low (3) and high-high (4) categories.\n\nquadrant[DV <0 & LM_I>0] <- 1\nquadrant[DV >0 & LM_I<0] <- 2\nquadrant[DV <0 & LM_I<0] <- 3  \nquadrant[DV >0 & LM_I>0] <- 4      \n\nLastly, places non-significant Moran in the category 0.\n\nquadrant[localMI[,5]>signif] <- 0\n\n\n\n5.3.4 Plotting LISA map\nUsing the code chunk below, we will build the LISA map. For effective interpretation, it is better to plot both the local Moran’s I values map and its corresponding p-values map next to each other.\n\nwpt_nonfunctional <- qtm(nga_wp, \"wpt_non-functional\")\n\nnga_wp.localMI$quadrant <- quadrant\ncolors <- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters <- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\nLISAmap <- tm_shape(nga_wp.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\nLISAmap\n\n\n\n\n5.4 Hot and Cold Spot Analysis\nIn order to detect spatial anomalies, we will use Getis and Ord’s G-Statistics. We will look at neighbours within a defined proximity to identify where either high or low values cluster spatially. Here, statistically significant hot-spots are recognised as areas of high values where other areas within a neighbourhood range also share high values too.\n\n5.4.1 Deriving the centroid\nThe code chunk below allows to get the longitude and latitude, which is the 1st value and 2nd value in each centroid respectively.\n\nlongitude <- map_dbl(nga_wp$geometry, ~st_centroid(.x)[[1]])\n\nlatitude <- map_dbl(nga_wp$geometry, ~st_centroid(.x)[[2]])\n\nNext we will use cbind to put the longitude and latitude into the same object.\n\ncoords <- cbind(longitude, latitude)\nhead(coords)\n\n\n\n5.4.2 Computing cut-off distance\nThe code chunk below uses dnearneigh() of spdep package to derive distance-based weight matrix.\n\nk1 <- knn2nb(knearneigh(coords))\n\nk1dists <- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\nThe summary report shows that the largest first nearest neighbour distance is 71.661 km, so using this as the upper threshold gives certainty that all units will have at least one neighbour.\n\n\n5.4.3 Computing fixed distance weight matrix\nThe chunk below computes the distance weight matrix by using dnearneigh() of spdep package.\nNext, we will use str() to display the content of wm_d72 weight matrix.\n\nwm_d72 <- dnearneigh(coords, 0, 72, longlat = TRUE)\nwm_d72\n\nnb2listw() is used to convert the nb object into spatial weights object.\n\nwm72_lw <- nb2listw(wm_d72, style = 'B')\nsummary(wm72_lw)\n\n\n\n5.4.4 Computing Gi statistics using fixed distance\n\nfips <- order(nga_wp$ADM2_EN)\ngi.fixed <- localG(nga_wp$'wpt non-functional', wm72_lw)\ngi.fixed\n\nThe Gi statistics is represented as a Z-score. Greater values represent a greater intensity of clustering and the direction (positive or negative) indicates high or low clusters.\nNext, we will join the Gi values to their corresponding nga_wp sf data frame by using the code chunk below.\n\nnga_wp.gi <- cbind(nga_wp, as.matrix(gi.fixed)) %>%\n  rename(gstat_fixed = as.matrix.gi.fixed.)\n\n\n\n5.4.5 Mapping Gi values using fixed distance\nThe code chunk below shows the functions used to map the Gi values derived using fixed distance weight matrix.\n\nwpt_nonfunctional <- qtm(nga_wp, \"wpt_non-functional\")\n\nGimap <-tm_shape(nga_wp.gi) +\n  tm_fill(col = \"gstat_fixed\", \n          style = \"pretty\",\n          palette=\"-RdBu\",\n          title = \"local Gi\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(Gimap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n1f2a596 (Commit)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home Ex2.html",
    "href": "Take-Home_Ex/Take-Home Ex2.html",
    "title": "Take-Home Exercise 2 - Geospatial Analytics for Social Good",
    "section": "",
    "text": "The process of creating regions is called regionalisation. A regionalisation is a special kind of clustering where the objective is to group observations which are similar in their statistical attributes, but also in their spatial location. In this sense, regionalization embeds the same logic as standard clustering techniques, but also applies a series of geographical constraints. Often, these constraints relate to connectivity: two candidates can only be grouped together in the same region if there exists a path from one member to another member that never leaves the region. These paths often model the spatial relationships in the data, such as contiguity or proximity. However, connectivity does not always need to hold for all regions, and in certain contexts it makes sense to relax connectivity or to impose different types of geographic constraints.\n\n\n\nThis study aims to apply appropriate clustering techniques to reveal the spatial patterns of water points in Nigeria.\n\n\n\nUsing the appropriate R packages, we will need to:\n\nPrepare the dataset and save it in simple feature data frameformat, as well as derive the proportion of functional and non-functional water point at LGA level\nConduct thematic mapping analysis to examine the spatial distribution of water points at LGA level\nConduct hotspot areas and outliers/clusters maps of water points at LGA level"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home Ex2.html#setup",
    "href": "Take-Home_Ex/Take-Home Ex2.html#setup",
    "title": "Take-Home Exercise 2 - Geospatial Analytics for Social Good",
    "section": "2. Setup",
    "text": "2. Setup\n\n2.1 Packages Used\nThe R packages that we will be using for this analysis area:\n\nsf, rgdal: used for importing, managing, and processing geospatial data\nspdep: used for computing spatial weights, global and local spatial auto-correlation statistics\ntidyverse: used for wrangling attribute data\ntmap: used for creating cartographic quality choropleth map\ncoorplot, ggpubr, heatmaply: used for multivariate data visualization and analysis\ncluster, ClustGeo: used for cluster analysis\nfunModeling: used for exploratory data analysis, data preparation and model performance\n\nIn addition, the following tidyverse packages will be used:\n\nreadr for reading rectangular data from csv, tsv and fwf\ntidyr for manipulating and tidying data\ndplyr for wrangling and transforming data\nggplot2 for visualising data\n\n\n\n2.2 Datasets Used\n2 geospatial datasets will be utilized for this study:\n\ngeo_export_338e5689-bd72-4866-bfde-8997933e9897\nWPdx+ dataset from WPdx Global Data Repositories\nnga_admbnda_adm2_osgof_20190417\nNigeria Level-2 Administrative Boundary (also known as Local Government Area) polygon features GIS data from geoBoundaries\n\n\n\n2.3 Launching the packages in R\nThe code chunk below is used to perform the following tasks:\n\ncreating a package list containing the necessary R packages,\nchecking if the R packages in the package list have been installed in R,\n\nif they have yet to be installed, RStudio will installed the missing packages,\n\nlaunching the packages into R environment.\n\n\npacman::p_load(rgdal, sf, spdep, tmap, tidyverse, ClustGeo, ggpubr, cluster, factoextra, NbClust, heatmaply, corrplot, psych, GGally, funModeling)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home Ex2.html#data-preparation",
    "href": "Take-Home_Ex/Take-Home Ex2.html#data-preparation",
    "title": "Take-Home Exercise 2 - Geospatial Analytics for Social Good",
    "section": "3. Data Preparation",
    "text": "3. Data Preparation\nIn this section, we will bring geospatial data into R environment. The geospatial data is in ESRI shapefile format.\n\n3.1 Import water point shapefile into R environment\nThe code chunk below uses st_read() of sf package to import Nigeria shapefile into R. The imported shapefile will be simple features Object of sf.\n\nwp2 <- st_read(dsn = \"geodata\",\n              layer = \"geo_export_338e5689-bd72-4866-bfde-8997933e9897\",\n              crs = 4326) %>%\n  filter(clean_coun == \"Nigeria\") %>%\n  select(1, 3:4, 11:15, 23, 36:40, 43:50)\n\nThe code chunk below uses write_rds() of readr package to save the extracted sf data table (i.e. wp) into an output in rds data format. The output file is called wp_nga2.rds and it is saved in geodata sub-folder.\n\nwp_nga2 <- write_rds(wp2, \"geodata/wp_nga2.rds\")\n\n\n\n3.2 Import Nigeria LGA boundary data into R environment\nWe are going to import LGA boundary data into R environment using the following code chunk, st_read() of sf package. It is used to import nga_admbnda_adm2_osgof_20190417 shapefile and save the imported geospatial data into simple feature data table.\n\nnga2 <- st_read(dsn = \"geodata\",\n               layer = \"nga_admbnda_adm2_osgof_20190417\",\n               crs = 4326)\n\n\n\n3.3 Recoding NA values into string\nUse replace_na() to recode all the NA values in status_cle field into the Unknown.\n\nwp_nga2 <- read_rds(\"geodata/wp_nga2.rds\") %>%\n  mutate(status_cle = replace_na(status_cle, \"Unknown\")) \n\n\n\n3.4 Checking of duplicated area name\nWe will order our dataframe by alphabetical order based on ADM2_REF and use the duplicated function to retrieve all ADM2_REF that has duplicates and store it in a list.\n\nnga2 <- (nga2[order(nga2$ADM2_REF), ])\n\nduplicate_area <- nga2$ADM2_REF [nga2$ADM2_REF %in%\n                  nga2$ADM2_REF[duplicated(nga2$ADM2_REF)]]\n\nduplicate_area\n\nFrom the results, we identified 12 ADM2_REF that are duplicates. We will then leverage on interactive view of tmap to check the location of each area. With the help of Google Map, we will retrieve the actual name and state of these areas.\n\n\n\nIndex\nActual Area Name\n\n\n\n\n94\nBassa (Kogi)\n\n\n95\nBassa (Plateau)\n\n\n304\nIfelodun (Kwara)\n\n\n305\nIfelodun (Osun)\n\n\n355\nIrepodun (Kawara)\n\n\n356\nIrepodun (Osun)\n\n\n519\nNasarawa (Kano)\n\n\n520\nNasarawa West\n\n\n546\nObi (Benue)\n\n\n547\nObi (Nasarawa)\n\n\n693\nSurulere (Lagos)\n\n\n694\nSurulere (Oyo)\n\n\n\n\ntmap_mode(\"view\")\n\ntm_shape(nga2[nga2$ADM2_REF %in% duplicate_area,]) +\n  tm_polygons()\n\n\ntmap_mode(\"plot\")\n\nWe will now access the individual index of the nga2 data frame and change the value. Lastly, we use the length() function to ensure there is no more duplicated ADM2_REF.\n\nnga2$ADM2_REF[c(94,95,304,305,355,356,519,546,547,693,694)] <- c(\"Bassa (Kogi)\",\"Bassa (Plateau)\", \"Ifelodun (Kwara)\",\"Ifelodun (Osun)\", \"Irepodun (Kwara)\",\"Irepodun (Osun)\", \"Nasarawa (Kano)\",\"Obi (Benue)\",\"Obi(Nasarawa)\", \"Surulere (Lagos)\",\"Surulere (Oyo)\")\n\nlength((nga2$ADM2_REF[ nga2$ADM2_REF %in% nga2$ADM2_REF[duplicated(nga2$ADM2_REF)] ]))\n\n\n\n3.5 Perform data binning for usage capacity field\nBefore we perform data binning, we will review the summary statistics of usage capacity field using the code chunk below. Based on the We will then use cut() function to categorize the values under usage_cap field to <1000 and >=1000.\n\nsummary(wp_nga2$usage_cap)\n\nwp_nga2 <- wp_nga2 %>% \n  mutate(usage_cap_bin = cut(usage_cap, breaks = c(0, 999, Inf), labels = c(\"<1000\", \">=1000\")))"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home Ex2.html#exploratory-data-analysis-via-statistical-graphics",
    "href": "Take-Home_Ex/Take-Home Ex2.html#exploratory-data-analysis-via-statistical-graphics",
    "title": "Take-Home Exercise 2 - Geospatial Analytics for Social Good",
    "section": "4. Exploratory Data Analysis via Statistical Graphics",
    "text": "4. Exploratory Data Analysis via Statistical Graphics\nUse freq() of funModeling package to display the distribution of status_cle, X_water_tec, usage_cap_bin, is_urban field in wp_nga2.\n\nfreq(data = wp_nga2,\n     input = \"status_cle\")\n\nfreq(data = wp_nga2,\n     input = \"X_water_tec\")\n\nfreq(data = wp_nga2,\n     input = \"usage_cap_bin\")\n\nfreq(data = wp_nga2,\n     input = \"is_urban\")\n\n\n4.1 Extract functional water point data\nIn the code chunk below, filter() of dplyr is used to select functional water points.\n\nwpt_functional <- wp_nga2 %>%\n  filter(status_cle %in%\n           c(\"Functional\", \n             \"Functional but not in use\",\n             \"Functional but needs repair\"))\n\nfreq(data=wpt_functional, \n     input = 'status_cle')\n\n\n\n4.2 Extract non-functional water point data\nIn the code chunk below, filter() of dplyr is used to select non-functional water points.\n\nwpt_nonfunctional <- wp_nga2 %>%\n  filter(status_cle %in%\n           c(\"Abandoned/Decommissioned\", \n             \"Abandoned\",\n             \"Non-Functional\",\n             \"Non functional due to dry season\",\n             \"Non-Functional due to dry season\"))\n\nfreq(data=wpt_nonfunctional, \n     input = 'status_cle')\n\n\n\n4.3 Extract water point data with Unknown class\nIn the code chunk below, filter() of dplyr is used to select unknown water points.\n\nwpt_unknown <- wp_nga2 %>%\n  filter(status_cle == \"Unknown\")\n\n\n\n4.4 Extract water point data with Hand Pump technology\nIn the code chunk below, filter() of dplyr is used to select hand pump water points.\n\nwpt_handpump <- wp_nga2 %>%\n  filter(X_water_tec == \"Hand Pump\")\n\n\n\n4.5 Extract LGA usage capacity\nIn the code chunk below, filter() of dplyr is used to select LGA usage capacities for <1000 and >=1000 respectively.\n\nlga_usage_cap_below1000 <- wp_nga2 %>%\n  filter(usage_cap_bin == \"<1000\")\n\nlga_usage_cap_atleast1000 <- wp_nga2 %>%\n  filter(usage_cap_bin == \">=1000\")\n\n\n\n4.6 Extract rural water points\nIn the code chunk below, filter() of dplyr is used to select rural water points.\n\nwpt_rural <- wp_nga2 %>%\n  filter(is_urban == \"False\")\n\n\n\n4.7 Performing Point-in-Polygon Count\nThe code chunk below performs 2 operations at one go. Firstly, it uses st_intersects() to identify the various water point types (e.g. total, functional, non-functional, hand pump), usage capacity and rural water points located inside each LGA boundary. Next, length() of Base R is used to calculate the number of water points that fall within each LGA boundary.\n\nnga_wp2 <- nga2 %>% \n  mutate(`total wpt` = lengths(\n    st_intersects(nga2, wp_nga2))) %>%\n  mutate(`wpt functional` = lengths(\n    st_intersects(nga2, wpt_functional))) %>%\n  mutate(`wpt non-functional` = lengths(\n    st_intersects(nga2, wpt_nonfunctional))) %>%\n  mutate(`wpt unknown` = lengths(\n    st_intersects(nga2, wpt_unknown))) %>%\n  mutate(`wpt handpump` = lengths(\n    st_intersects(nga2, wpt_handpump))) %>%\n  mutate(`lga usage cap b1000` = lengths(\n    st_intersects(nga2, lga_usage_cap_below1000))) %>%\n  mutate(`lga usage cap a1000` = lengths(\n    st_intersects(nga2, lga_usage_cap_atleast1000))) %>%\n  mutate(`wpt rural` = lengths(\n    st_intersects(nga2, wpt_rural)))\n\n\n\n4.8 Saving the Analytical Data Table\nThe code chunk below uses mutate() of dplyr package to derive 6 fields namely pct_functional, pct_non-functional, pct_handpump, pct_usagecap_below1000, pct_usagecap_atleast1000 and pct_rural. In order to keep the file size small, select() of dplyr is used to retain on the relevant fields.\n\nnga_wp2 <- nga_wp2 %>%\n  mutate(pct_functional = `wpt functional`/`total wpt`) %>%\n  mutate(`pct_non-functional` = `wpt non-functional`/`total wpt`) %>%\n  mutate(`pct_handpump` = `wpt handpump`/`total wpt`) %>%\n  mutate(`pct_usagecap_below1000` = `lga usage cap b1000`/`total wpt`) %>%\n  mutate(`pct_usagecap_atleast1000` = `lga usage cap a1000`/`total wpt`) %>%\n  mutate(`pct_rural` = `wpt rural`/`total wpt`)\n\nThereafter, we will save the sf data table in rds format for subsequent analysis.\n\nwrite_rds(nga_wp2, \"geodata/nga_wp2.rds\")"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home Ex2.html#exploratory-spatial-data-analysis-via-choropleth-map",
    "href": "Take-Home_Ex/Take-Home Ex2.html#exploratory-spatial-data-analysis-via-choropleth-map",
    "title": "Take-Home Exercise 2 - Geospatial Analytics for Social Good",
    "section": "5. Exploratory Spatial Data Analysis via Choropleth Map",
    "text": "5. Exploratory Spatial Data Analysis via Choropleth Map\n\n5.1 Preparing a choropleth map - Functional Water Points\nTo take a quick look at the distribution of the water points in LGA of Nigeria, a choropleth map will be prepared. The code chunks below are used to prepare the choropleth by using qtm() function of tmap package.\n\nqtm(nga_wp2, \"pct_functional\")\n\nIn order to assess the level of bias in the dataset for functional water points, we will create two choropleth maps, one for the total functional water points and one for the percentage of functional water points by using the code chunk below.\n\ntm_shape(nga_wp2) +\n    tm_polygons(c(\"wpt functional\", \"pct_functional\"),\n              style = \"jenks\") +\n    tm_facets(sync = TRUE, ncol = 2) +\n  tm_legend(legend.position = c(\"right\", \"bottom\")) +\n  tm_layout(outer.margins=0, asp=0)\n\nBased on the results above, it shows that there is a higher concentration of functional water points in the northern part of Nigeria.\n\n\n5.2 Preparing a choropleth map - Non-Functional Water Points\nSimilar to Point 5.1, we will use similar code chunks to prepare choropleth map for non-functional water points.\n\nqtm(nga_wp2, \"pct_non-functional\")\n\nIn order to assess the level of bias in the dataset for non-functional water points, we will create two choropleth maps, one for the total non-functional water points and one for the percentage of non-functional water points by using the code chunk below.\n\ntm_shape(nga_wp2) +\n    tm_polygons(c(\"wpt non-functional\", \"pct_non-functional\"),\n              style = \"jenks\") +\n    tm_facets(sync = TRUE, ncol = 2) +\n  tm_legend(legend.position = c(\"right\", \"bottom\")) +\n  tm_layout(outer.margins=0, asp=0)\n\nBased on the results above, it shows that there is a higher concentration of non-functional water points in the southern part of Nigeria.\n\n\n5.3 Preparing a choropleth map - Handpump Water Points\nSimilar to Point 5.1, we will use similar code chunks to prepare choropleth map for handpump water points.\n\nqtm(nga_wp2, \"pct_handpump\")\n\n\ntm_shape(nga_wp2) +\n    tm_polygons(c(\"wpt handpump\", \"pct_handpump\"),\n              style = \"jenks\") +\n    tm_facets(sync = TRUE, ncol = 2) +\n  tm_legend(legend.position = c(\"right\", \"bottom\")) +\n  tm_layout(outer.margins=0, asp=0)\n\nBased on the results above, it shows that there is a higher concentration of handpump water points in the northern part of Nigeria i.e. regions with lower GDP.\n\n\n5.4 Preparing a choropleth map - Usage Capacity Below 1000\nSimilar to Point 5.1, we will use similar code chunks to prepare choropleth map for water points with usage capacity below 1000.\n\nqtm(nga_wp2, \"pct_usagecap_below1000\")\n\n\ntm_shape(nga_wp2) +\n    tm_polygons(c(\"lga usage cap b1000\", \"pct_usagecap_below1000\"),\n              style = \"jenks\") +\n    tm_facets(sync = TRUE, ncol = 2) +\n  tm_legend(legend.position = c(\"right\", \"bottom\")) +\n  tm_layout(outer.margins=0, asp=0)\n\nBased on the results above, water points with usage capacity below 1000 are quite prevalent across Nigeria especially in the northern and south-eastern part of Nigeria.\n\n\n5.5 Preparing a choropleth map - Usage Capacity At Least 1000\nSimilar to Point 5.1, we will use similar code chunks to prepare choropleth map for water points with usage capacity at least 1000.\n\nqtm(nga_wp2, \"pct_usagecap_atleast1000\")\n\n\ntm_shape(nga_wp2) +\n    tm_polygons(c(\"lga usage cap a1000\", \"pct_usagecap_atleast1000\"),\n              style = \"jenks\") +\n    tm_facets(sync = TRUE, ncol = 2) +\n  tm_legend(legend.position = c(\"right\", \"bottom\")) +\n  tm_layout(outer.margins=0, asp=0)\n\nBased on the results above, water points with usage capacity at least 1000 are quite prevalent in the southern part of Nigeria.\n\n\n5.6 Preparing a choropleth map - Rural Water Points\nSimilar to Point 5.1, we will use similar code chunks to prepare choropleth map for rural water points.\n\nqtm(nga_wp2, \"pct_rural\")\n\n\ntm_shape(nga_wp2) +\n    tm_polygons(c(\"wpt rural\", \"pct_rural\"),\n              style = \"jenks\") +\n    tm_facets(sync = TRUE, ncol = 2) +\n  tm_legend(legend.position = c(\"right\", \"bottom\")) +\n  tm_layout(outer.margins=0, asp=0)\n\nBased on the results above, rural water points are quite prevalent across of Nigeria."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home Ex2.html#correlation-analysis",
    "href": "Take-Home_Ex/Take-Home Ex2.html#correlation-analysis",
    "title": "Take-Home Exercise 2 - Geospatial Analytics for Social Good",
    "section": "6. Correlation Analysis",
    "text": "6. Correlation Analysis\nBased on choropleth maps in Section 5, there are missing values. We will replace all the NaN values with Null values.\n\nnga_wp2$pct_functional[is.nan(nga_wp2$pct_functional)] <-0\nnga_wp2$`pct_non-functional`[is.nan(nga_wp2$`pct_non-functional`)] <-0\nnga_wp2$pct_handpump[is.nan(nga_wp2$pct_handpump)] <-0\nnga_wp2$pct_usagecap_below1000[is.nan(nga_wp2$pct_usagecap_below1000)] <-0\nnga_wp2$pct_usagecap_atleast1000[is.nan(nga_wp2$pct_usagecap_atleast1000)] <-0\nnga_wp2$pct_rural[is.nan(nga_wp2$pct_rural)] <-0\n\nBefore we perform cluster analysis, it is important for us to ensure that the cluster variables are not highly correlated. We will use corrplot.mixed() function of corrplot package to visualise and analyse the correlation of the input variables.\n\ncluster_vars.cor = cor(st_set_geometry(nga_wp2[,26:31], NULL))\n  corrplot.mixed(cluster_vars.cor,\n         lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\nThe correlation plot above shows that pct_usagecap_below1000 and pct_usagecap_atleast1000 are highly correlated (>0.85). This suggest that only one of them should be used in the cluster analysis instead of both."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home Ex2.html#hierarchy-cluster-analysis",
    "href": "Take-Home_Ex/Take-Home Ex2.html#hierarchy-cluster-analysis",
    "title": "Take-Home Exercise 2 - Geospatial Analytics for Social Good",
    "section": "7. Hierarchy Cluster Analysis",
    "text": "7. Hierarchy Cluster Analysis\nWe will perform hierarchical cluster analysis on the dataset.\n\n7.1 Extracting clustering variables\nThe code chunk below will be used to extract the clustering variables from the nga_wp2 simple feature object into data.frame.\n\ncluster_vars <- nga_wp2 %>%\n  st_set_geometry(NULL) %>%\n  select(\"ADM2_REF\", \"pct_functional\", \"pct_non-functional\", \"pct_handpump\", \"pct_usagecap_below1000\", \"pct_rural\")\nhead(cluster_vars,10)\n\nWe need to change the rows by township name instead of row number. Thereafter, we will delete the ADM2_REF field by using the code chunk below.\n\nrow.names(cluster_vars) <- cluster_vars$\"ADM2_REF\"\nhead(cluster_vars,10)\n\nnga_wp2_hc <- select(cluster_vars, c(2:6))\nhead(nga_wp2_hc, 10)\n\n\n\n7.2 Visualizing raw values without data standardization\nWe will now visualize the various raw values using ggplot() function. Based on the histogram, it seems like there is a need to standardize the values.\n\nf <- ggplot(data = nga_wp2_hc, \n             aes(x= `pct_functional`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Raw values without standardisation - Functional\")\n\nnf <- ggplot(data = nga_wp2_hc, \n             aes(x= `pct_non-functional`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Raw values without standardisation - Non-Functional\")\n\nh <- ggplot(data = nga_wp2_hc, \n             aes(x= `pct_handpump`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Raw values without standardisation - Handpump\")\n\nucap <- ggplot(data = nga_wp2_hc, \n             aes(x= `pct_usagecap_below1000`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Raw values without standardisation - Usage Cap Below 1000\")\n\nr <- ggplot(data = nga_wp2_hc, \n             aes(x= `pct_rural`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Raw values without standardisation - Rural\")\n\nggarrange(f, nf, h, ucap, r,\n          ncol = 3,\n          nrow = 2)\n\n\n\n7.3 Z-score standardization\nThe code chunk below will be used to stadardisation the clustering variables by using Z-score method.\n\nnga_wp2_hc.z <- scale(nga_wp2_hc)\ndescribe(nga_wp2_hc.z)\n\n\n\n7.4 Visualizing standardized clustering variables\nThe code chunk below plot the 5 scaled fields.\n\nnga_wp2_hc_z_df <- as.data.frame(nga_wp2_hc.z)\nfz <- ggplot(data=nga_wp2_hc_z_df, \n       aes(x=`pct_functional`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Z-score Standardisation - Functional\")\n\nnga_wp2_hc_z_df <- as.data.frame(nga_wp2_hc.z)\nnfz <- ggplot(data=nga_wp2_hc_z_df, \n       aes(x=`pct_non-functional`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Z-score Standardisation - Non-Functional\")\n\nnga_wp2_hc_z_df <- as.data.frame(nga_wp2_hc.z)\nhz <- ggplot(data=nga_wp2_hc_z_df, \n       aes(x=`pct_handpump`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Z-score Standardisation - Handpump\")\n\nnga_wp2_hc_z_df <- as.data.frame(nga_wp2_hc.z)\nucapz <- ggplot(data=nga_wp2_hc_z_df, \n       aes(x=`pct_usagecap_below1000`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Z-score Standardisation - Usage Cap Below 1000\")\n\nnga_wp2_hc_z_df <- as.data.frame(nga_wp2_hc.z)\nrz <- ggplot(data=nga_wp2_hc_z_df, \n       aes(x=`pct_rural`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Z-score Standardisation - Rural\")\n\nggarrange(fz, nfz, hz, ucapz, rz,\n          ncol = 3,\n          nrow = 2)\n\n\n\n7.5 Computing proximity matrix\nWe will compute the proximity matrix by using dist() of R. The code chunk below is used to compute the proximity matrix using euclidean method.\n\nproxmat <- dist(nga_wp2_hc_z_df, method = 'euclidean')\n\nproxmat\n\n\n\n7.6 Computing hierarchical clustering\nWe will use hclust() of R stats to compute hierarchical clustering.The code chunk below performs hierarchical cluster analysis using ward.D method. The hierarchical clustering output is stored in an object of class hclust which describes the tree produced by the clustering process.\n\nhclust_ward <- hclust(proxmat, method = 'ward.D')\n\nWe can then plot the tree by using plot() of R Graphics as shown in the code chunk below.\n\nplot(hclust_ward, cex = 0.1)\n\n\n\n7.7 Selecting the optimal clustering algorithm\nThe code chunk below will be used to compute the agglomerative coefficients of all hierarchical clustering algorithms (values closer to 1 suggest strong clustering structure).\n\nm <- c( \"average\", \"single\", \"complete\", \"ward\")\nnames(m) <- c( \"average\", \"single\", \"complete\", \"ward\")\n\nac <- function(x) {\n  agnes(nga_wp2_hc_z_df, method = x)$ac\n}\n\nmap_dbl(m, ac)\n\nWith reference to the output above, we can see that Ward’s method provides the strongest clustering structure among the four methods assessed. Hence, in the subsequent analysis, only Ward’s method will be used.\n\n\n7.8 Determining Optimal Clusters\nWe will use gap statistic method to help determine the optimal cluster. To compute the gap statistic, clusGap() of cluster package will be used.\n\nset.seed(12345)\ngap_stat <- clusGap(nga_wp2_hc_z_df, \n                    FUN = hcut, \n                    nstart = 25, \n                    K.max = 20, \n                    B = 50)\n# Print the result\nprint(gap_stat, method = \"firstmax\")\n\nAlso note that the hcut function used is from factoextra package.\nNext, we can visualise the plot by using fviz_gap_stat() of factoextra package.\n\nfviz_gap_stat(gap_stat)\n\nBy examine the gap statistic graph, the 18-cluster gives the largest gap statistic and should be the next best cluster to pick.\n\n\n7.9 Visually-driven hierarchical clustering analysis\nWe will apply heatmaply package to build both highly interactive cluster heatmap or static cluster heatmap.\n\n7.9.1 Transforming the data frame into a matrix\nThe data was loaded into a data frame, but it has to be a data matrix to make your heatmap.\nThe code chunk below will be used to transform nga_wp2_hc_z_df data frame into a data matrix.\n\nnga_wp2_hc_z_df_mat <- data.matrix(nga_wp2_hc_z_df)\n\n\n\n7.9.2 Plotting interactive cluster heatmap using heatmaply()\nIn the code chunk below, the heatmaply() of heatmaply package is used to build an interactive cluster heatmap.\n\nheatmaply(normalize(nga_wp2_hc_z_df_mat),\n          Colv=NA,\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\",\n          seriate = \"OLO\",\n          colors = Blues,\n          k_row = 18,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"Geographic Segmentation of Nigeria State by different indicators\",\n          xlab = \"Different Indicators\",\n          ylab = \"Townships of Nigeria State\"\n          )\n\nBased on the results above, it show that the many regions in Nigeria has a high correlation with pct_rural variables compared to pct_non-functional variables.\n\n\n\n7.10 Mapping the clusters formed\nWith closed examination of the dendragram above, we have decided to retain 18 clusters.\ncutree() of R Base will be used in the code chunk below to derive a 18-cluster model.\n\ngroups <- as.factor(cutree(hclust_ward, k=18))\n\nThe code chunk below form the join in three steps:\n\nthe groups list object will be converted into a matrix;\ncbind() is used to append groups matrix onto nga_wp2 to produce an output simple feature object called nga_wp2_cluster; and\nrename of dplyr package is used to rename as.matrix.groups field as CLUSTER.\n\n\nnga_wp2_cluster <- cbind(nga_wp2, as.matrix(groups)) %>%\n  rename(`CLUSTER`=`as.matrix.groups.`)\n\nNext, qtm() of tmap package is used to plot the choropleth map showing the cluster formed.\n\nqtm(nga_wp2_cluster, \"CLUSTER\")\n\nThe choropleth map above reveals the clusters are very fragmented, especiallyin the central and southern part of Nigeria. There seems to be a more homogeneous distribution of similar clusters in the northern part of Nigeria."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home Ex2.html#spatially-constrained-clustering-clustgeo-method",
    "href": "Take-Home_Ex/Take-Home Ex2.html#spatially-constrained-clustering-clustgeo-method",
    "title": "Take-Home Exercise 2 - Geospatial Analytics for Social Good",
    "section": "8. Spatially Constrained Clustering: ClustGeo Method",
    "text": "8. Spatially Constrained Clustering: ClustGeo Method\nUsing the ClustGeo package to perform non-spatially constrained hierarchical cluster analysis and spatially constrained cluster analysis.\n\n8.1 Ward-like hierarchical clustering: ClustGeo\nTo perform non-spatially constrained hierarchical clustering, we only need to provide the function a dissimilarity matrix as shown in the code chunk below.\n\nnongeo_cluster <- hclustgeo(proxmat)\nplot(nongeo_cluster, cex = 0.5)\nrect.hclust(nongeo_cluster, \n            k = 18, \n            border = 2:5)\n\n\n\n8.2 Mapping the clusters formed\n\ngroups <- as.factor(cutree(nongeo_cluster, k=18))\n\nnga_wp2_ngeo_cluster <- cbind(nga_wp2, as.matrix(groups)) %>%\n  rename(`CLUSTER` = `as.matrix.groups.`)\n\nqtm(nga_wp2_ngeo_cluster, \"CLUSTER\")\n\n\n\n8.3 Spatially Constrained Hierarchical Clustering\nBefore we can performed spatially constrained hierarchical clustering, a spatial distance matrix will be derived by using st_distance() of sf package.\n\ndist <- st_distance(nga_wp2, nga_wp2)\ndistmat <- as.dist(dist)\n\nNotice that as.dist() is used to convert the data frame into matrix.\nNext, choicealpha() will be used to determine a suitable value for the mixing parameter alpha as shown in the code chunk below.\n\ncr <- choicealpha(proxmat, distmat, range.alpha = seq(0, 1, 0.1), K=18, graph = TRUE)\n\nWith reference to the graphs above, alpha = 0.35 will be used as shown in the code chunk below.\n\nclustG <- hclustgeo(proxmat, distmat, alpha = 0.35)\n\nNext, cutree() is used to derive the cluster object.\n\ngroups <- as.factor(cutree(clustG, k=18))\n\nWe will then join back the group list with nga_wp2 polygon feature data frame by using the code chunk below.\n\nnga_wp2_Gcluster <- cbind(nga_wp2, as.matrix(groups)) %>%\n  rename(`CLUSTER` = `as.matrix.groups.`)\n\nWe can now plot the map of the newly delineated spatially constrained clusters. Based on the figure below, it shows that the clusters are less fragmented.\n\nqtm(nga_wp2_Gcluster, \"CLUSTER\")\n\n\n\n8.4 Multivariate Visualization\nFor the code chunk below, we will use ggparcoord() of GGally package to create parallel coordinate plots as part of revealing clustering variables by clusters.\n\nggparcoord(data = nga_wp2_Gcluster, \n           columns = c(25:28,30), \n           scale = \"globalminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of 5 Different Variables by Cluster\") +\n  facet_grid(~ CLUSTER) + \n  theme(axis.text.x = element_text(angle = 90))\n\nBased on the results above, it shows that townships in Cluster 3, 4, 9, 10, 14, and 18 of Nigeria tend to have a higher proportion of functional water points. However Cluster 3, 4, 10 and 14 exhibit lower proportion of usage capacity below 1000.\nIn the code chunk below, group_by() and summarise() of dplyr are used to derive mean values of the clustering variables.\n\nnga_wp2_Gcluster %>% \n  st_set_geometry(NULL) %>%\n  group_by(CLUSTER) %>%\n  summarise(mean_pct_functional = mean(pct_functional),\n            mean_pct_non.functional = mean(pct_non.functional),\n            mean_pct_handpump = mean(pct_handpump),\n            mean_pct_usagecap_below1000 = mean(pct_usagecap_below1000),\n            mean_pct_rural = mean(pct_rural))"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home Ex2.html#conclusion",
    "href": "Take-Home_Ex/Take-Home Ex2.html#conclusion",
    "title": "Take-Home Exercise 2 - Geospatial Analytics for Social Good",
    "section": "9. Conclusion",
    "text": "9. Conclusion\nIn summary, spatially constrained clustering is useful in segmenting geographical populations for better allocation of resources. The use of hierarchical clustering via agglomerative approach helps to group dissimilar groups together with no apriori information about the number of clusters required."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home Ex2.html#future-work",
    "href": "Take-Home_Ex/Take-Home Ex2.html#future-work",
    "title": "Take-Home Exercise 2 - Geospatial Analytics for Social Good",
    "section": "10. Future Work",
    "text": "10. Future Work\nTo further enhance the quality of data analysis, I proposed the following areas:\n\nSocio-demographics - Instead of looking at the proportion of water points and technology of water points, we can attempt to understand socio-demographics of the population e.g. affluence, GDP per capita, population size etc. Given that Nigeria is a relatively large country, each region has its separate set of needs and thus consumption behaviour of water points.\nk-nearest neighbour - I would also propose to have more samples for different neighbours to compare the results as this will help strengthen the justification of high priority regions that requires attention."
  }
]